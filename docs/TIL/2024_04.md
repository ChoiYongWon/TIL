# 2024. 04.

## 04. 01.

### File vs Blob

File 객체는 Blob객체를 상속받은 객체이며 Blob의 모든 속성을 다 갖고 있음  
Blob이 파일 그 자체의 데이터라면 File은 메타데이터 등 부가 데이터가 존재함.  

### FileReader.readDataAsUrl vs URL.createObjectURL

다른건 없다. readDataAsUrl는 비동기적으로 처리하고 createObjectURL는 동기적으로 처리한다.  


## 04. 02.

### s3-presigned-post vs s3-request-presigner

presigned url을 사용해야하는데 두가지 방식이 보였다.  
`s3-request-presigner`는 PUT 메소드를 사용하고 만료 시간밖에 정하지 못하는 반면 `s3-presigned-post`는 POST 메소드를 사용하여 더 많은 제약 조건을 설정할 수 있다. `s3-request-presigner`의 상위 호환 느낌이다.

[s3-request-presigner AWS 공식문서](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/Package/-aws-sdk-s3-request-presigner/)  
[s3-presigned-post AWS 공식문서](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/Package/-aws-sdk-s3-presigned-post/)  

[POST 메소드를 활용한 제약조건 예시](https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html)  

[S3-Presigned-Url-도입하기](https://velog.io/@invidam/S3-Presigned-Url-%EB%8F%84%EC%9E%85%ED%95%98%EA%B8%B0)  


## 04. 03.

### 이미지 압축 처리에 대한 고민

사용자가 이미지와 게시물을 업로드할때 이미지를 압축하고 싶다.  
클라이언트에서 하기엔 사용자 경험이 안좋고, 서버에서 하기엔 효율이 떨어지는 느낌이다.  

AWS lambda를 사용하여 s3에 origin 버킷으로 이미지가 업로드 되었을 때 동작하여 이미지를 압축하여 resize 버킷으로 재 업로드하는 전략이다.  
resize 버킷으로의 업로드 성공 후 게시물을 업로드 하고싶다.  



### lambda 에서 sharp로 이미지 압축

> 최신 버전의 sharp(0.33)는 Lambda와 호환되지 않는다. `0.32.6` 버전을 사용해야한다.

```sh

npm install --arch=x64 --platform=linux --target=16x sharp@0.32.6

```


[더 나은 사용자 경험을 위한 이미지 리사이징을 해보자](https://medium.com/@wj2kim/%EB%8D%94-%EB%82%98%EC%9D%80-%EC%82%AC%EC%9A%A9%EC%9E%90-%EA%B2%BD%ED%97%98%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%A6%AC%EC%82%AC%EC%9D%B4%EC%A7%95%EC%9D%84-%ED%95%B4%EB%B3%B4%EC%9E%90-cffbb55b9d95)  
[자습서: Amazon S3 트리거를 사용하여 썸네일 이미지 생성](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-s3-tutorial.html)  

### NextJS Image Optimizing

알아보니 NextJS에서 remote 이미지도 최적화 해준다. 이러한 이유로 next.config.js에 Next Image에서 사용하는 src의 도메인을 작성하라고 하는것 같다.  
동작 방식은 클라이언트에서 이미지를 요청하면 Next Server에서 이미지를 요청하여 자체적으로 최적화해서 브라우저에 제공해주는걸로 보인다.  

Next Server와 Next Client간의 로딩은 빠르겠지만 Next Server와 S3(이미지 저장소)간의 통신은 S3에 이미지를 압축해서 저장하지 않으면 여전히 느리고 비용도 많이 나올것으로 보인다.  
일단 Next에서 제공해주는 최적화 방식을 사용해보고 문제가 있다 싶으면 바꾸자.  

Next Server에서 자체적으로 압축해줄때 기본적으로 squoosh를 쓰는데 sharp가 더 성능이 좋다고 매우 추천하니 써보자.

## 04. 04.

### presigned URL에 업로드할 때 Condition Content-Type issue

presigned url 생성 시  
Condition (제약조건)은 다음과 같다.

```js
const Conditions: any = [
    ["eq", "$acl", "public-read"], 
    ["eq", "$bucket", process.env.AWS_S3_BUCKET as string], // 버킷
    ["starts-with", "$Content-Type", "image/"], // 이미지 타입만
    ["starts-with", "$key", `user/${session.user.id}/`], // 사용자 폴더에만
];

```

업로드 요청 후 s3에서 에러가 날아왔다.  

```xml
<Error>
    <Code>AccessDenied</Code>
    <Message>Invalid according to Policy: Policy Condition failed: ["starts-with", "$Content-Type", "image/"]</Message>
    <RequestId>0CPB85WE4SJQ18GW</RequestId>
    <HostId>o2mMEAUT0jrGx+eOnaPkPPZRNJKncnjDHZwkjsM3bMCzxa/d0cWNkQy9BfkVThuzvu0iuNx7P3o=</HostId>
</Error>
```

axios에 요청 때 Content-Type를 바꿔서 보냈는데 안되었고

```js
form.append('file', file);
form.append('Content-Type', type)
```

Form 타입에 이와 같이 기입해줘었는데 에러가 났다.  

```js
form.append('Content-Type', type)
form.append('file', file);
```

순서 바꿔주니까 되더라  
어이없음.

## 04. 05.

### 클라이언트에서 이미지를 압축하는 짓은 하지 말자.  

프론트에 이미지 업로드하고 다른 작업을 할 동안 백그라운드에서 압축하는 로직을 넣어봤다.  

<iframe src="https://www.youtube.com/embed/BS9jeIm0ZkY" class="iframe"frameborder="0" allowfullscreen="true"></iframe>   

화면 밑에 보면 압축 큐가 비어있으면 true, 이미지 압축이 진행되고 있으면 false이다.     

테스트 결과, 데스크탑 환경에서는 아무 렉 없이 잘되는데 모바일 환경에서는 백그라운드에서 압축할 동안 다른 작업이 안된다.   
멀티쓰레드로 동작한다지만 안그래도 없는 메모리 web worker가 다 잡아먹어서 그런것 같다.   

내 3시간.

## 04. 06.

### upload image to s3 via cloudfront

s3와 cloudfront를 연결한 상태에서 presigned url을 사용해서 업로드를 할려니 에러가 난다.  

```xml
<?xml version="1.0" encoding="UTF-8"?>
<Error>
    <Code>InvalidArgument</Code>
        <Message>x-amz-content-sha256 must be UNSIGNED-PAYLOAD, STREAMING-UNSIGNED-PAYLOAD-TRAILER, STREAMING-AWS4-HMAC-SHA256-PAYLOAD, STREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER, STREAMING-AWS4-ECDSA-P256-SHA256-PAYLOAD, STREAMING-AWS4-ECDSA-P256-SHA256-PAYLOAD-TRAILER or a valid sha256 value.
        </Message>
    <ArgumentName>x-amz-content-sha256<ArgumentName>
    <ArgumentValue>null</ArgumentValue>
    <RequestId>C3B2DY8CB4FZ4N40</RequestId>
    <HostId>SgOlN+Wp+2kbRHOaPfywiIMg2f8mwabKW+Ex3AUtrUuMXbdxnpq7zM5xYIM9DydChOjr77MlTlw=</HostId>
</Error>
```   

몇몇 글을 보면서 삽질을 해보았다.  

[Uploading into S3 directly vs through CloudFront](https://www.reddit.com/r/aws/comments/13efai9/uploading_into_s3_directly_vs_through_cloudfront/)   
[Patterns for building an API to upload files to Amazon S3](https://aws.amazon.com/ko/blogs/compute/patterns-for-building-an-api-to-upload-files-to-amazon-s3/)  
[Using CloudFront to upload files to S3 bucket using presign URL and custom domain](https://repost.aws/questions/QUK6WNxu6XQsSmGgljY5de9w/using-cloudfront-to-upload-files-to-s3-bucket-using-presign-url-and-custom-domain)

첫번째 글에서 cloudfront를 통해 업로드하는 방법은 바람직하지 못한 방법이라고 언급하였고 (업로드 시 캐싱 이득을 못보기 때문)  
두번째 글에서는 s3에 업로드하는 다양한 패턴들을 소개하는데 cloutfront를 통해 업로드하는 경우는 없었다.  
세번째 글은 그냥 긴가민가하다.

생각해본 결과, 이미지 get은 cloudfront로 하되, 업로드는 s3의 presigned url로 하도록하는게 해답인것 같다.  

### CloudFront를 통해서만 S3 객체 접근

CloudFront로 s3를 연결했고 get은 CloudFront의 url로만, upload는 s3의 presigned url로만 하고 싶었다.  

버킷 권한 설정을 다음과 같이하고

> 객체를 get하는 요청은 CloudFront로부터만 받겠다.


```json

{
    "Version": "2008-10-17",
    "Id": "PolicyForCloudFrontPrivateContent",
    "Statement": [
        {
            "Sid": "AllowCloudFrontServicePrincipal",
            "Effect": "Allow",
            "Principal": {
                "Service": "cloudfront.amazonaws.com"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::a-spot-thur/*",
            "Condition": {
                "StringEquals": {
                    "AWS:SourceArn": "arn:aws:cloudfront::533267392768:distribution/E2C03KKK1Y4NIL"
                }
            }
        }
    ]
}

```   

버킷 권한을 다음과 같이 해주었다.

![](https://github.com/ChoiYongWon/TIL/assets/40623433/5aa6e8c1-2092-402e-a53c-b4530f621179)   

> 모든 객체에 대해 퍼블릭 액세스를 무시한다.  


이러면 모든 객체에 대한 퍼블릭 액세스는 무시되고 버킷 정책이 적용되어 CloudFront를 통해서면 객체에 접근(get)할 수 있다.  

야매로 읽고 하긴헀는데, 
조만간 버킷 퍼블릭 엑세스에 대해서 더 공부해야겠다.

## 04. 07.

### Object.keys는 O(n)이다.

객체의 길이를 가져오고 싶어서 `Object.keys(obj)`를 사용해서 길이를 구했다.

```js
const obj = {
    '1': 4,
    '2': 6
}
console.log(Object.keys(obj).length)
// 2
```

이는 O(n)의 시간복잡도를 갖고있으므로 반복문 내에서 사용하면 비효율적이다.

<!-- ### react query isSuccess는 언제 false가 될까 -->

## 04. 08.

### prisma migrate dev vs prisma migrate deploy

prisma 스키마를 작성하고 실제 db에 반영시키는 두가지 방법이다.  

```
npx prisma migrate dev
```
- shadoww db에서 기존 마이그레이션 기록을 전부 재실행
- shadow db에 보류중인 마이그레이션 모두 적용
- 스키마에 변경이 생겼을 경우 새 마이그레이션 생성
- 모든 마이그레이션 적용 후 _prisma_migrations 에 기록
- prisma client 재 생성
- 마이그레이션 적용 시 모든 데이터 리셋

```
npx prisma migrate dev --create-only
```

`--create-only` 명령어를 사용하면 원격으로 적용하지 않고 마이그레이션을 생성한다.

```
npx prisma migrate deploy
```
- 보류중인 마이그레이션을 적용한다
- 데이터베이스를 리셋하지 않는다
- shadow db에 의존하지 않는다

## 04. 09.

### NextJS multi root layout 간의 라우팅

NextJS에서 Multi root layout 구조에서 root 간의 이동은 전체 페이지가 다시 로드된다 (캐싱이 안됨). `Link` 컴포넌트나 `route prefetch` 메소드로도 안통함.

Multi root layout 구조에서만 해당됨.

## 04. 10.

### NextJS 14에서 커스텀 metadata (google) 추가

크롬으로 접속할때 항상 번역 팝업이 떠서 짜증나서 비활성화하려고 메타데이터에 `google: notranslate`를 추가해야되는데 NextJS에 기본 제공되는 필드가 아니었다.

![](https://github.com/ChoiYongWon/AT/assets/40623433/e689be5e-7fa2-403c-8a91-b2eed727daa1)

NextJS 14에서 메타데이터를 추가하려면 기본 제공되는 메타 데이터들을 활용해야한다.  
그 이 외의 데이터들은 [other](https://nextjs.org/docs/app/api-reference/functions/generate-metadata#other) 필드를 사용해서 추가하면 된다.  

```js
export const metadata: Metadata = {
  title: "AT - A Spot Thur",
  description: "나만의 지도를 만들어보세요!",
  other: {
    google: 'notranslate'
  }
};
```

## 04. 13

### Tanstack Query useQuery 캐싱

useQuery가 자동으로 refetch 하는 경우는 다음과 같다. 우선 데이터가 Stale 상태여야하고, 
- 네트워크 재연결
- 윈도우 재포커스
- 컴포넌트 마운트
- refetchInterval


수동으로 refetch하는 과정은 useQuery에서 제공하는 refetch 함수를 실행하면 된다.  
refetch 함수를 실행하면 일단 기존 캐시값을 반환하고 백그라운드에서 최신 데이터를 가져와서 캐시를 업데이트한다.  

(확실하지 않음) useQuery 함수에 enabled를 false로 주면 useQuery가 위와 같이 자동으로 refetch 하지 않으므로 수동(refetch 함수)으로 호출해야 된다.  

[[TIL-35] react-query와 검색 기능에서의 캐싱 처리](https://junvelee.tistory.com/129)  
[[React Query] 리액트 쿼리 '잘' 사용해보자 - 네트워크 비용 감소 / UX 개선](https://heycoding.tistory.com/128)  

### Tanstack Query useQuery 상태

상태는 총 4가지
- `Fresh`
- `Fetching`
- `Stale`
- `Pause`
- `Inactive`

`Stale`은 Fresh의 반대이며, `Stale` 상태에 있으면 데이터가 신선하지 않다는 뜻이다 (오래된 데이터)  

staleTime이 지나면 데이터는 더이상 Fresh하지 않다.   

query가 언마운트되면 쿼리는 `Inactive` 상태가 되며 gcTime이 지나면 아예 삭제된다.  

`Stale`과 `Fresh` 상태는 `Inactive` 상태여도 기억하고 있다가, 다시 마운트되면 반영된다.  
즉, staleTime이 Infinity면 `Inactive`된 상태에서 다시 마운트가 되어도 재요청하지 않는다.   
반대로 stale 상태의 쿼리가 언마운트되어 `Inactive`가 되었다면 이 후에 마운트 되면 다시 refetch된다.   

staleTime과 gcTime을 Infinity로 두면 처음 요청 이외에는 자동으로 요청하지 않는다.(데이터가 계속 `Fresh`하기 때문) -> refetch 함수로 캐시를 업데이트할 수 있다. (refetch 함수는 캐시가 있더라도 최신 데이터로 다시 업데이트 하기 때문)  
 

[Tanstack Query Caching Examples](https://tanstack.com/query/latest/docs/framework/react/guides/caching?from=reactQueryV3)  


## 04. 15.

### 리액트 생명주기

### useState 구조